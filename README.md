# ğŸš¨ Blue/Green Observability & Alerting System
## DevOps Intern â€” Stage 3 Task

This project extends the Stage 2 Blue/Green deployment by adding observability, monitoring, and alerting.
It introduces a real-time Python log-watcher sidecar that tails Nginx logs, detects failovers or high error rates, and sends formatted alerts to Slack under the name Blueprint.

## ğŸ§­ Overview

When running a Blue/Green setup, visibility into whatâ€™s happening behind the Nginx load balancer is crucial.
This stage provides that visibility by:
- Enriching Nginx access logs with detailed upstream metadata.
- Streaming logs to a lightweight watcher container.
- Automatically notifying Slack when failovers occur or when error rates exceed a configured threshold.

The result is a self-observing deployment environment â€” you know which pool is serving traffic, how healthy it is, and when to take action.

## ğŸ§± Architecture
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Slack Channel      â”‚
                â”‚  (Blueprint Alerts)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Webhook (JSON)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx      â”‚â”€â”€â”€â”€â–¶â”‚ Python Watcher  â”‚
â”‚  (Access Log)â”‚     â”‚  tails log,     â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”‚  detects events â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                   â”‚
     â–¼                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Shared Volume
â”‚ Blue Service â”‚
â”‚ Green Serviceâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Nginx writes structured logs (pool, release, status, latency).
- Watcher reads those logs in real time, maintains a rolling window, and evaluates conditions.
- Slack Webhook receives formatted alerts posted as Blueprint.

## âš™ï¸ Features
Failover Detection:	Detects when traffic flips from one pool (e.g. Blue â†’ Green).
Error-Rate Monitoring:	Watches the last `N` requests for 5xx responses and alerts when they exceed threshold.
Slack Notifications:	Sends clean, structured alerts using Block Kit formatting.
Maintenance Mode:	Suppresses alerts during planned toggles.
Environment-Driven Configuration:	All thresholds and webhook details come from `.env`.

## ğŸ“ Repository Layout
.
â”œâ”€â”€ docker-compose.yml        # Defines Blue, Green, Nginx, and Watcher services
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf.template   # Structured logging format
â”‚   â””â”€â”€ docker-entrypoint.sh  # Generates upstream config dynamically
â”œâ”€â”€ watcher/
â”‚   â”œâ”€â”€ watcher.py            # Main alert engine
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ runbook.md                # Operator guide for responding to alerts
â”œâ”€â”€ .env.example              # Config variables and defaults
â””â”€â”€ tests/
    â””â”€â”€ high_error_rate.sh    # Simple load test to trigger alerts

## âš™ï¸ Environment Variables

SLACK_WEBHOOK_URL:  Webhook URL for posting alerts	(required)
ACTIVE_POOL	Initial:    active pool (blue or green)
ERROR_RATE_THRESHOLD:   % of 5xx requests to trigger alert	2
WINDOW_SIZE:	Number of recent requests to evaluate	200
ALERT_COOLDOWN_SEC:	Cooldown between repeated alerts (s)	300
MAINTENANCE_MODE:	Suppress alerts when true	false
LOG_PATH:	Path to Nginx access log	/var/log/nginx/access.log

## ğŸš€ Getting Started

1. Set up Slack Webhook

- Create an [Incoming Webhook](https://api.slack.com/apps)
- Enable it for a channel (e.g., #alerts).
- Copy the generated URL into .env under SLACK_WEBHOOK_URL.

2. Configure Environment
```
cp .env.example .env
# Edit values as needed
```

3. Launch the Stack
```
docker compose up -d
```

4. Verify Components
```
docker compose ps
docker logs -f alert_watcher
docker exec -it nginx tail -n 5 /var/log/nginx/access.log
```

You should see logs being written and the watcher printing updates.

## ğŸ”” Alert Behavior
### ğŸš¨ Failover Alerts

Triggered when the active pool flips (e.g., Blue â†’ Green).

Slack Message Example

> ğŸ”´ Failover Detected
> â€¢ From: `Blue â†’ Green`
> â€¢ Time: 2025-10-30 16:03 UTC
> Action: Verify primary container health and traffic routing.

### âš ï¸ Error-Rate Alerts

Triggered when 5xx responses exceed the threshold (default 2 %) within the sliding window.

Slack Message Example

> ğŸŸ  High Upstream Error Rate Detected
> â€¢ Rate: 6.50 % over 200 requests
> â€¢ Threshold: 2 %
> Action: Check upstream logs and investigate errors.

ğŸ’¤ Maintenance Mode

Set `MAINTENANCE_MODE=true` in `.env` to silence alerts during planned releases.

## ğŸ§ª Testing Alerts
**Simulate Failover**

Bring down the currently active container:
```
docker stop app_blue
```

Nginx will failover to the other pool, and the watcher posts a failover alert.

**Simulate High Error-Rate**

Run the included test script to generate many requests:
```
bash tests/high_error_rate.sh
```

If enough requests return 5xx, youâ€™ll receive a â€œHigh Error Rateâ€ alert in Slack.

## ğŸ“– Runbook (summary)

See `runbook.md` for detailed operator steps:

- What each alert means
- How to inspect logs and containers
- Recovery and escalation procedures